{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "690e5d50",
   "metadata": {},
   "source": [
    "# Preprocessing the ASL Alphabet Dataset\n",
    "\n",
    "This notebook demonstrates how to preprocess the ASL Alphabet Dataset, including loading, resizing, normalizing, label encoding, and augmenting images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d063d",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "This code cell imports all the necessary libraries for data preprocessing, including TensorFlow, NumPy, and scikit-learn components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269724c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d725bab",
   "metadata": {},
   "source": [
    "## Define Dataset Loading Function\n",
    "\n",
    "This function will load the ASL dataset from the specified directory. It will be implemented to read images and their corresponding labels from the folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b346135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_dir):\n",
    "    \"\"\"\n",
    "    Load the ASL dataset from the specified directory.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): Path to the dataset directory\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (images, labels) - Arrays of images and their corresponding labels\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label_dir in os.listdir(data_dir):\n",
    "        label_path = os.path.join(data_dir, label_dir)\n",
    "        if os.path.isdir(label_path):\n",
    "            for image_file in os.listdir(label_path):\n",
    "                image_path = os.path.join(label_path, image_file)\n",
    "                image = tf.keras.preprocessing.image.load_img(image_path)\n",
    "                images.append(tf.keras.preprocessing.image.img_to_array(image))\n",
    "                labels.append(label_dir)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79bad60",
   "metadata": {},
   "source": [
    "## Define Image Resizing Function\n",
    "\n",
    "This function resizes all images to a consistent size (224x224 pixels) to ensure uniform input for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d505e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(images, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Resize images to a consistent target size.\n",
    "    \n",
    "    Args:\n",
    "        images (array): Array of images to resize\n",
    "        target_size (tuple): Target size (height, width)\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Array of resized images\n",
    "    \"\"\"\n",
    "    resized_images = [tf.image.resize(image, target_size) for image in images]\n",
    "    return np.array(resized_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d26b0c",
   "metadata": {},
   "source": [
    "## Define Image Normalization Function\n",
    "\n",
    "This function normalizes pixel values from the range [0, 255] to [0, 1] to improve neural network training performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8d9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(images):\n",
    "    \"\"\"\n",
    "    Normalize pixel values from [0, 255] to [0, 1].\n",
    "    \n",
    "    Args:\n",
    "        images (array): Array of images to normalize\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Array of normalized images\n",
    "    \"\"\"\n",
    "    normalized_images = images / 255.0\n",
    "    return normalized_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fe22ef",
   "metadata": {},
   "source": [
    "## Define Label Encoding Function\n",
    "\n",
    "This function converts text labels (A, B, C, etc.) into numerical values that can be used by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b67ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(labels):\n",
    "    \"\"\"\n",
    "    Encode text labels into numerical values.\n",
    "    \n",
    "    Args:\n",
    "        labels (array): Array of text labels (e.g., ['A', 'B', 'C'])\n",
    "        \n",
    "    Returns:\n",
    "        array: Encoded numerical labels\n",
    "    \"\"\"\n",
    "    encoder = LabelEncoder()\n",
    "    encoded_labels = encoder.fit_transform(labels)\n",
    "    return encoded_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3175745b",
   "metadata": {},
   "source": [
    "## Define Data Augmentation Function\n",
    "\n",
    "This function applies data augmentation techniques (rotation, shifting, flipping) to increase the diversity of the training data and improve model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e177026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_images(images):\n",
    "    \"\"\"\n",
    "    Apply data augmentation to images.\n",
    "    \n",
    "    Args:\n",
    "        images (array): Array of images to augment\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Array of augmented images\n",
    "    \"\"\"\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    augmented_images = [datagen.random_transform(image) for image in images]\n",
    "    return np.array(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6694e4",
   "metadata": {},
   "source": [
    "## Demonstrate Complete Preprocessing Pipeline\n",
    "\n",
    "This function demonstrates the complete preprocessing pipeline by applying all the preprocessing steps to a sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a10bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_preprocessing(data_dir):\n",
    "    \"\"\"\n",
    "    Demonstrate the complete preprocessing pipeline on a sample dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): Path to the dataset directory\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Processed images and encoded labels ready for training\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    sample_images, sample_labels = load_dataset(data_dir)\n",
    "    \n",
    "    # Apply preprocessing steps\n",
    "    resized_images = resize_images(sample_images)\n",
    "    normalized_images = normalize_images(resized_images)\n",
    "    augmented_images = augment_images(normalized_images)\n",
    "    encoded_labels = encode_labels(sample_labels)\n",
    "    \n",
    "    print(\"Preprocessing complete. Sample images ready for training.\")\n",
    "    print(f\"Processed {len(augmented_images)} images\")\n",
    "    print(f\"Image shape: {augmented_images[0].shape}\")\n",
    "    print(f\"Number of unique labels: {len(np.unique(encoded_labels))}\")\n",
    "    \n",
    "    return augmented_images, encoded_labels\n",
    "\n",
    "# Example usage\n",
    "DATA_DIR = \"../data/asl_alphabet_train/asl_alphabet_train\"\n",
    "processed_images, processed_labels = demonstrate_preprocessing(DATA_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
