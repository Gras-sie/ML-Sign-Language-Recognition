{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "690e5d50",
   "metadata": {},
   "source": [
    "# Preprocessing the ASL Alphabet Dataset\n",
    "\n",
    "This notebook demonstrates how to preprocess the ASL Alphabet Dataset, including loading, resizing, normalizing, label encoding, and augmenting images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d063d",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "This code cell imports all the necessary libraries for data preprocessing, including TensorFlow, NumPy, and scikit-learn components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269724c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of data directory:\n",
      "- asl_alphabet_test (directory)\n",
      "- asl_alphabet_train (directory)\n",
      "- README.md (file)\n",
      "\n",
      "Contents of C:/Users/User/OneDrive - belgiumcampus.ac.za/Marius_Grassman/ML-Sign-Language-Recognition/data/asl_alphabet_train:\n",
      "- asl_alphabet_train (directory)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Debugging code to check the directory structure and contents\n",
    "base_path = \"C:/Users/User/OneDrive - belgiumcampus.ac.za/Marius_Grassman/ML-Sign-Language-Recognition/data/\"\n",
    "print(\"Contents of data directory:\")\n",
    "for item in os.listdir(base_path):\n",
    "    item_path = os.path.join(base_path, item)\n",
    "    print(f\"- {item} {'(directory)' if os.path.isdir(item_path) else '(file)'}\")\n",
    "\n",
    "train_path = os.path.join(base_path, \"asl_alphabet_train\")\n",
    "if os.path.exists(train_path):\n",
    "    print(f\"\\nContents of {train_path}:\")\n",
    "    for item in os.listdir(train_path):\n",
    "        item_path = os.path.join(train_path, item)\n",
    "        print(f\"- {item} {'(directory)' if os.path.isdir(item_path) else '(file)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d725bab",
   "metadata": {},
   "source": [
    "## Define Dataset Loading Function\n",
    "\n",
    "This function will load the ASL dataset from the specified directory. It will be implemented to read images and their corresponding labels from the folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b346135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_dir, max_images_per_class=50):\n",
    "    \"\"\"\n",
    "    Load a limited number of images per class from the ASL dataset directory.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): Path to the dataset directory\n",
    "        max_images_per_class (int): Maximum images to load per class\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (images, labels) - Arrays of images and their corresponding labels\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label_dir in os.listdir(data_dir):\n",
    "        label_path = os.path.join(data_dir, label_dir)\n",
    "        if os.path.isdir(label_path):\n",
    "            count = 0\n",
    "            for image_file in os.listdir(label_path):\n",
    "                if count >= max_images_per_class:\n",
    "                    break\n",
    "                image_path = os.path.join(label_path, image_file)\n",
    "                try:\n",
    "                    image = tf.keras.preprocessing.image.load_img(image_path)\n",
    "                    images.append(tf.keras.preprocessing.image.img_to_array(image))\n",
    "                    labels.append(label_dir)\n",
    "                    count += 1\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79bad60",
   "metadata": {},
   "source": [
    "## Define Image Resizing Function\n",
    "\n",
    "This function resizes all images to a consistent size (224x224 pixels) to ensure uniform input for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d505e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(images, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Resize images to a consistent target size.\n",
    "    \n",
    "    Args:\n",
    "        images (array): Array of images to resize\n",
    "        target_size (tuple): Target size (height, width)\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Array of resized images\n",
    "    \"\"\"\n",
    "    resized_images = [tf.image.resize(image, target_size) for image in images]\n",
    "    return np.array(resized_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d26b0c",
   "metadata": {},
   "source": [
    "## Define Image Normalization Function\n",
    "\n",
    "This function normalizes pixel values from the range [0, 255] to [0, 1] to improve neural network training performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a8d9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(images):\n",
    "    \"\"\"\n",
    "    Normalize pixel values from [0, 255] to [0, 1].\n",
    "    \n",
    "    Args:\n",
    "        images (array): Array of images to normalize\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Array of normalized images\n",
    "    \"\"\"\n",
    "    normalized_images = images / 255.0\n",
    "    return normalized_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fe22ef",
   "metadata": {},
   "source": [
    "## Define Label Encoding Function\n",
    "\n",
    "This function converts text labels (A, B, C, etc.) into numerical values that can be used by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "512b67ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(labels):\n",
    "    \"\"\"\n",
    "    Encode text labels into numerical values.\n",
    "    \n",
    "    Args:\n",
    "        labels (array): Array of text labels (e.g., ['A', 'B', 'C'])\n",
    "        \n",
    "    Returns:\n",
    "        array: Encoded numerical labels\n",
    "    \"\"\"\n",
    "    encoder = LabelEncoder()\n",
    "    encoded_labels = encoder.fit_transform(labels)\n",
    "    return encoded_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3175745b",
   "metadata": {},
   "source": [
    "## Define Data Augmentation Function\n",
    "\n",
    "This function applies data augmentation techniques (rotation, shifting, flipping) to increase the diversity of the training data and improve model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e177026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_images(images):\n",
    "    \"\"\"\n",
    "    Apply data augmentation to images.\n",
    "    \n",
    "    Args:\n",
    "        images (array): Array of images to augment\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Array of augmented images\n",
    "    \"\"\"\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    augmented_images = [datagen.random_transform(image) for image in images]\n",
    "    return np.array(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6694e4",
   "metadata": {},
   "source": [
    "## Demonstrate Complete Preprocessing Pipeline\n",
    "\n",
    "This function demonstrates the complete preprocessing pipeline by applying all the preprocessing steps to a sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a10bb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Sample images ready for training.\n",
      "Processed 1450 images\n",
      "Image shape: (224, 224, 3)\n",
      "Number of unique labels: 29\n"
     ]
    }
   ],
   "source": [
    "def demonstrate_preprocessing(data_dir):\n",
    "    \"\"\"\n",
    "    Demonstrate the complete preprocessing pipeline on a sample dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): Path to the dataset directory\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Processed images and encoded labels ready for training\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    sample_images, sample_labels = load_dataset(data_dir)\n",
    "    \n",
    "    # Apply preprocessing steps\n",
    "    resized_images = resize_images(sample_images)\n",
    "    normalized_images = normalize_images(resized_images)\n",
    "    augmented_images = augment_images(normalized_images)\n",
    "    encoded_labels = encode_labels(sample_labels)\n",
    "    \n",
    "    print(\"Preprocessing complete. Sample images ready for training.\")\n",
    "    print(f\"Processed {len(augmented_images)} images\")\n",
    "    print(f\"Image shape: {augmented_images[0].shape}\")\n",
    "    print(f\"Number of unique labels: {len(np.unique(encoded_labels))}\")\n",
    "    \n",
    "    return augmented_images, encoded_labels\n",
    "\n",
    "# Example usage\n",
    "# Use the correct path to the actual image folders, not the parent directory\n",
    "DATA_DIR = \"C:/Users/User/OneDrive - belgiumcampus.ac.za/Marius_Grassman/ML-Sign-Language-Recognition/data/asl_alphabet_train/asl_alphabet_train/\"\n",
    "processed_images, processed_labels = demonstrate_preprocessing(DATA_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
