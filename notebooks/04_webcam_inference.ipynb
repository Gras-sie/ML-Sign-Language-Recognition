{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "290b8c9e",
   "metadata": {},
   "source": [
    "# Real-Time ASL Detection Using Webcam\n",
    "\n",
    "This notebook demonstrates how to use a trained CNN model to detect static ASL signs in real-time using a webcam. OpenCV is used for video capture and preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c8d3a6",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "This code cell imports all the necessary libraries for webcam-based ASL detection, including OpenCV for video processing and TensorFlow for model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0c569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98658cb",
   "metadata": {},
   "source": [
    "## Load the Trained Model\n",
    "\n",
    "This function loads the trained CNN model from a specified path and prepares it for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(model_path):\n",
    "    \"\"\"\n",
    "    Load the trained CNN model from a specified path.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Path to the saved model file\n",
    "        \n",
    "    Returns:\n",
    "        tensorflow.keras.Model: Loaded model ready for inference\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        print(f\"Model loaded successfully from: {model_path}\")\n",
    "        print(f\"Model input shape: {model.input_shape}\")\n",
    "        print(f\"Model output shape: {model.output_shape}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0f4e2",
   "metadata": {},
   "source": [
    "## Create Label Mapping\n",
    "\n",
    "This function creates a mapping from numerical predictions to actual letters (A-Z) for displaying results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2ac029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_mapping():\n",
    "    \"\"\"\n",
    "    Create a mapping from numerical predictions to letters.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary mapping indices to letters (0->A, 1->B, etc.)\n",
    "    \"\"\"\n",
    "    # Create mapping for A-Z (26 classes)\n",
    "    label_map = {i: letter for i, letter in enumerate(string.ascii_uppercase)}\n",
    "    return label_map\n",
    "\n",
    "# Create the label mapping\n",
    "LABEL_MAP = create_label_mapping()\n",
    "print(\"Label mapping created:\")\n",
    "print(LABEL_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dec9ef3",
   "metadata": {},
   "source": [
    "## Preprocess Image for Inference\n",
    "\n",
    "This function preprocesses a single image frame for model inference by resizing and normalizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc73850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Preprocess a video frame for model inference.\n",
    "    \n",
    "    Args:\n",
    "        frame (np.array): Input frame from webcam\n",
    "        target_size (tuple): Target size for resizing\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Preprocessed frame ready for inference\n",
    "    \"\"\"\n",
    "    # Resize the frame\n",
    "    resized_frame = cv2.resize(frame, target_size)\n",
    "    \n",
    "    # Normalize pixel values to [0, 1]\n",
    "    normalized_frame = resized_frame / 255.0\n",
    "    \n",
    "    # Add batch dimension\n",
    "    input_frame = np.expand_dims(normalized_frame, axis=0)\n",
    "    \n",
    "    return input_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b80162",
   "metadata": {},
   "source": [
    "## Test Model on Sample Image\n",
    "\n",
    "This function tests the trained model on a sample image to verify its functionality before starting real-time detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3f3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_on_sample_image(model, sample_image_path, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Test the trained model on a sample image.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained CNN model\n",
    "        sample_image_path (str): Path to the sample image\n",
    "        target_size (tuple): Target size for resizing\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and preprocess the sample image\n",
    "        sample_image = cv2.imread(sample_image_path)\n",
    "        if sample_image is None:\n",
    "            print(f\"Error: Could not load image from {sample_image_path}\")\n",
    "            return\n",
    "        \n",
    "        input_image = preprocess_frame(sample_image, target_size)\n",
    "        \n",
    "        # Run inference\n",
    "        predictions = model.predict(input_image)\n",
    "        predicted_index = np.argmax(predictions)\n",
    "        predicted_letter = LABEL_MAP[predicted_index]\n",
    "        confidence = predictions[0][predicted_index]\n",
    "        \n",
    "        print(f\"Predicted letter: {predicted_letter}\")\n",
    "        print(f\"Confidence: {confidence:.4f}\")\n",
    "        print(f\"Top 3 predictions:\")\n",
    "        \n",
    "        # Show top 3 predictions\n",
    "        top_indices = np.argsort(predictions[0])[-3:][::-1]\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            letter = LABEL_MAP[idx]\n",
    "            conf = predictions[0][idx]\n",
    "            print(f\"  {i+1}. {letter}: {conf:.4f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during inference: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4d7520",
   "metadata": {},
   "source": [
    "## Set Up Real-Time Webcam Detection\n",
    "\n",
    "This function starts the webcam and performs real-time ASL sign detection, displaying the predicted letter on the video feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5584c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_webcam_detection(model, target_size=(224, 224), confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Start real-time ASL detection using webcam.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained CNN model\n",
    "        target_size (tuple): Target size for resizing frames\n",
    "        confidence_threshold (float): Minimum confidence to display prediction\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "        return\n",
    "    \n",
    "    print(\"Starting webcam detection...\")\n",
    "    print(\"Press 'q' to quit\")\n",
    "    print(\"Press 's' to save current frame\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture frame\")\n",
    "            break\n",
    "        \n",
    "        # Flip frame horizontally for mirror effect\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Preprocess the frame\n",
    "        input_frame = preprocess_frame(frame, target_size)\n",
    "        \n",
    "        # Run inference\n",
    "        predictions = model.predict(input_frame, verbose=0)\n",
    "        predicted_index = np.argmax(predictions)\n",
    "        predicted_letter = LABEL_MAP[predicted_index]\n",
    "        confidence = predictions[0][predicted_index]\n",
    "        \n",
    "        # Display prediction only if confidence is above threshold\n",
    "        if confidence > confidence_threshold:\n",
    "            text = f\"Letter: {predicted_letter} ({confidence:.2f})\"\n",
    "            color = (0, 255, 0)  # Green\n",
    "        else:\n",
    "            text = \"No confident prediction\"\n",
    "            color = (0, 255, 255)  # Yellow\n",
    "        \n",
    "        # Add text overlay\n",
    "        cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "        cv2.putText(frame, \"Press 'q' to quit\", (10, frame.shape[0] - 20), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "        \n",
    "        # Display the frame\n",
    "        cv2.imshow('ASL Real-Time Detection', frame)\n",
    "        \n",
    "        # Handle key presses\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('s'):\n",
    "            # Save current frame\n",
    "            filename = f\"captured_frame_{frame_count}.jpg\"\n",
    "            cv2.imwrite(filename, frame)\n",
    "            print(f\"Frame saved as {filename}\")\n",
    "            frame_count += 1\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Webcam detection stopped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19d603",
   "metadata": {},
   "source": [
    "## Complete Inference Pipeline Example\n",
    "\n",
    "This cell demonstrates how to use all the functions together to perform real-time ASL detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2162a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Complete Real-Time Inference Pipeline\n",
    "\n",
    "# Configuration\n",
    "MODEL_PATH = \"../models/asl_cnn_model.h5\"  # Path to your trained model\n",
    "CONFIDENCE_THRESHOLD = 0.7  # Minimum confidence for displaying predictions\n",
    "\n",
    "# Step 1: Load the trained model\n",
    "print(\"Loading trained model...\")\n",
    "model = load_trained_model(MODEL_PATH)\n",
    "\n",
    "if model is not None:\n",
    "    # Step 2: Start real-time webcam detection\n",
    "    print(\"\\nStarting real-time webcam detection...\")\n",
    "    start_webcam_detection(model, confidence_threshold=CONFIDENCE_THRESHOLD)\n",
    "else:\n",
    "    print(\"Failed to load model. Please check the model path.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
